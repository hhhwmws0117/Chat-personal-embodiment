{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 数字个人化身 Chat-personal-embodiment\n",
        "\n",
        "[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)]()\n",
        "[![Data License](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg)]()\n",
        "\n",
        "\n",
        "[数字个人化身项目](https://github.com/hhhwmws0117/Chat-personal-embodiment)由[Chat凉宫春日项目](https://github.com/LC1332/Chat-Haruhi-Suzumiya.git)中的在读学生组建，组队参加星火杯比赛的支线任务,对接讯飞星火大模型，独立推进本项目工作。\n",
        "\n",
        "本项目由[米唯实清华大学](https://github.com/hhhwmws0117)，[詹林康@凯斯西储大学](https://github.com/JunityZhan)，[闫晨曦@成都信息工程大学](https://github.com/todochenxi)，[沈骏一@浙江大学](https://github.com/J1shen)，[孙浩甄@天津大学](https://github.com/JcandZero)开发。"
      ],
      "metadata": {
        "id": "ZMpBs-ZgEFP1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYDpT-xbonpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a0378e-a753-42d0-e41d-05755d3b1ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio\n",
            "  Downloading gradio-3.44.4-py3-none-any.whl (20.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chatharuhi\n",
            "  Downloading chatharuhi-1.0.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.12-py3-none-any.whl (426 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.5/426.5 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.103.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.1 (from gradio)\n",
            "  Downloading gradio_client-0.5.1-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.12)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.1->gradio) (2023.6.0)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Collecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Collecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx->gradio) (1.1.3)\n",
            "Building wheels for collected packages: chatharuhi, pypika, ffmpy\n",
            "  Building wheel for chatharuhi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chatharuhi: filename=chatharuhi-1.0.2-py3-none-any.whl size=23565 sha256=f126e1e858697655f6394d5e93be68e64652722f2b069d04fcf3c1de56f3fdac\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ec/46/bbc8f0d877c4bfb188d1a2cf107f41cdc677985a317e7bf083\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=ebe1b1233099758c7e0eade633ec0ae2ad166906df2485e7069eb3e9a79bd515\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=79455a02c2fdc1a9651928bd8997a770732414026bb5b63dfb16fcfb960f291c\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built chatharuhi pypika ffmpy\n",
            "Installing collected packages: tokenizers, safetensors, pypika, pydub, monotonic, ffmpy, chatharuhi, websockets, uvloop, semantic-version, python-multipart, python-dotenv, pulsar-client, overrides, orjson, humanfriendly, httptools, h11, chroma-hnswlib, bcrypt, backoff, aiofiles, watchfiles, uvicorn, tiktoken, starlette, posthog, huggingface-hub, httpcore, coloredlogs, transformers, openai, onnxruntime, httpx, fastapi, gradio-client, chromadb, gradio\n",
            "Successfully installed aiofiles-23.2.1 backoff-2.2.1 bcrypt-4.0.1 chatharuhi-1.0.2 chroma-hnswlib-0.7.3 chromadb-0.4.12 coloredlogs-15.0.1 fastapi-0.99.1 ffmpy-0.3.1 gradio-3.44.4 gradio-client-0.5.1 h11-0.14.0 httpcore-0.18.0 httptools-0.6.0 httpx-0.25.0 huggingface-hub-0.17.2 humanfriendly-10.0 monotonic-1.6 onnxruntime-1.16.0 openai-0.28.0 orjson-3.9.7 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pydub-0.25.1 pypika-0.48.9 python-dotenv-1.0.0 python-multipart-0.0.6 safetensors-0.3.3 semantic-version-2.10.0 starlette-0.27.0 tiktoken-0.5.1 tokenizers-0.13.3 transformers-4.33.2 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.20.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai gradio chatharuhi chromadb transformers tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQMPqnYEuq4o"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = \"sk-l4VCV8cYvthXSXHq4dP\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZDBDcp8v-Md"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"APPID\"] = \"219faa1b\"\n",
        "os.environ[\"APISecret\"] = \"OWFmOGEwMzE3MmRj\"\n",
        "os.environ[\"APIKey\"] = \"b01212368a9a1f63\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "ARClzVomofv0",
        "outputId": "3f7a5b54-1b0e-4f3b-8a15-34272e6883f0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d56199c9ca2b>\u001b[0m in \u001b[0;36m<cell line: 212>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;31m# TODO2 现有的虚拟角色可以做为媒介，筛选出合适的用户作为推荐，或者说用户匹配的数据，要保存下来，用作推荐\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mq4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_custom_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiselect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mq4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf'_|_{q4.label}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             characters = gr.Dropdown([\"凉宫春日\", \"汤师爷\", \"慕容复\", \"李云龙\", \"Luna\", \"王多鱼\", \"Ron\",\n\u001b[1;32m    269\u001b[0m                                       \u001b[0;34m\"鸠摩智\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Snape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Malfoy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"虚竹\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"萧峰\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"段誉\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Hermione\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dumbledore\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'NoneType' and 'str'"
          ]
        }
      ],
      "source": [
        "from chatharuhi import ChatHaruhi\n",
        "from datetime import datetime\n",
        "import zipfile\n",
        "import os\n",
        "import requests\n",
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "NAME_DICT = {'汤师爷': 'tangshiye', '慕容复': 'murongfu', '李云龙': 'liyunlong', 'Luna': 'Luna',\n",
        "             '王多鱼': 'wangduoyu',\n",
        "             'Ron': 'Ron', '鸠摩智': 'jiumozhi', 'Snape': 'Snape',\n",
        "             '凉宫春日': 'haruhi', 'Malfoy': 'Malfoy', '虚竹': 'xuzhu', '萧峰': 'xiaofeng', '段誉': 'duanyu',\n",
        "             'Hermione': 'Hermione', 'Dumbledore': 'Dumbledore', '王语嫣': 'wangyuyan',\n",
        "             'Harry': 'Harry', 'McGonagall': 'McGonagall', '白展堂': 'baizhantang', '佟湘玉': 'tongxiangyu',\n",
        "             '郭芙蓉': 'guofurong', '旅行者': 'wanderer', '钟离': 'zhongli',\n",
        "             '胡桃': 'hutao', 'Sheldon': 'Sheldon', 'Raj': 'Raj', 'Penny': 'Penny', '韦小宝': 'weixiaobao',\n",
        "             '乔峰': 'qiaofeng', '神里绫华': 'ayaka', '雷电将军': 'raidenShogun', '于谦': 'yuqian'}\n",
        "\n",
        "\n",
        "# download all character zip file\n",
        "def download_character():\n",
        "    try:\n",
        "        os.makedirs(\"characters_zip\")\n",
        "    except:\n",
        "        pass\n",
        "    try:\n",
        "        os.makedirs(\"characters\")\n",
        "    except:\n",
        "        pass\n",
        "    ai_roles_obj = {}\n",
        "    for ai_role_en in NAME_DICT.values():\n",
        "        file_url = f\"https://github.com/LC1332/Haruhi-2-Dev/raw/main/data/character_in_zip/{ai_role_en}.zip\"\n",
        "        try:\n",
        "            os.makedirs(f\"characters/{ai_role_en}\")\n",
        "        except:\n",
        "            pass\n",
        "        if f\"{ai_role_en}.zip\" not in os.listdir(f\"characters_zip\"):\n",
        "            destination_file = f\"characters_zip/{ai_role_en}.zip\"\n",
        "            max_retries = 3  # 最大重试次数\n",
        "            for attempt in range(1, max_retries + 1):\n",
        "                response = requests.get(file_url)\n",
        "                if response.status_code == 200:\n",
        "                    with open(destination_file, \"wb\") as file:\n",
        "                        file.write(response.content)\n",
        "                    print(ai_role_en)\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"{ai_role_en}第{attempt}次下载失败\")\n",
        "            # wget.download(file_url, destination_file)  # 503\n",
        "            destination_folder = f\"characters/{ai_role_en}\"\n",
        "            with zipfile.ZipFile(destination_file, 'r') as zip_ref:\n",
        "                zip_ref.extractall(destination_folder)\n",
        "        # db_folder = f\"./characters/{ai_role_en}/content/{ai_role_en}\"\n",
        "        # system_prompt = f\"./characters/{ai_role_en}/content/system_prompt.txt\"\n",
        "        # ai_roles_obj[ai_role_en] = ChatHaruhi(system_prompt=system_prompt,\n",
        "        #                                       llm=\"openai\",\n",
        "        #                                       story_db=db_folder,\n",
        "        #                                       verbose=True)\n",
        "\n",
        "\n",
        "def chat_psychologist(nickname, year, month, day, sex, occupation, school, label, q1, q2, q3, q4, model=\"gpt-3.5-turbo\",\n",
        "                      dialogue_example=\"\"):\n",
        "    basic_question_list = [\"昵称\", \"生日\", \"性别\", \"职业\", \"学校\", \"标签\"]\n",
        "    basic_choice_list = [nickname, f\"{year}年{month}月{day}\", sex, occupation, school, label]\n",
        "    path = f\"characters/{nickname}\"\n",
        "    if os.path.exists(\"/content/\"+path):\n",
        "      psych_question_list = []\n",
        "      psych_choice_list = []\n",
        "\n",
        "      for i in range(len(os.listdir(path))):\n",
        "          filename = f\"{path}/{i}.txt\"\n",
        "          with open(filename, 'r', encoding='utf-8') as f:\n",
        "              lines = f.readlines()\n",
        "              psych_question = lines[0].strip('\\n').split(':')[1]\n",
        "              psych_choice = lines[1].strip('\\n').split(':')[1]\n",
        "\n",
        "              psych_question_list.append(psych_question)\n",
        "              psych_choice_list.append(psych_choice)\n",
        "              psych_choice_list[-1] = q4\n",
        "    else:\n",
        "      psych_question_list = [\"你平时的周末是怎么度过的？\", \"你对音乐的偏好是什么？\", \"你最喜欢的电影类型是什么？\"]\n",
        "      psych_choice_list = [q1, q2, q3]\n",
        "    system_prompt = \"我想让你扮演一个心理测量专家，请针对你的心理被测对象的基本特征和一些对于基本心里问题的回答进行工作,你面对的心理被测对象是一个具有如下基本特征的人：\\n\"\n",
        "    basic_result = \"\"\n",
        "    psych_result = \"\"\n",
        "\n",
        "    for i in range(len(basic_question_list)):\n",
        "        basic_result += f\"在 {basic_question_list[i]} 方面，被测者是 {basic_choice_list[i]}\\n\"\n",
        "\n",
        "    # print(basic_result)\n",
        "    prompt_link = \"以下是你已经对于被测者进行的一些测试和被测者的回答：\\n\"\n",
        "\n",
        "    for i in range(len(psych_question_list)):\n",
        "        psych_result += f\"对于 {psych_question_list[i]} 问题，被测者的回答是 {psych_choice_list[i]}\\n\"\n",
        "\n",
        "    prompt_control = \"请你根据以上信息进行心理测试，任务是模仿上述已经问过的问题给出你要问的下一个问题和三个你预设对方会回答的答案。\\n请以 **一个bullet** 的形式进行返回，该bullet有四项，第一项是下一个问题，后三项分别是你预设的回答。\\n例如：- 你对于小事是怎样的态度？\\n- 我会记住每一件小事\\n- 我对于小事并不在意\\n- 我会记住让我受触动的小事\\n\"\n",
        "    prompt = system_prompt + basic_result + prompt_link + psych_result + prompt_control\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    # print(prompt)\n",
        "    result_bullet = response.choices[0].message[\"content\"]\n",
        "    bullet_lines = result_bullet.split('\\n')  # 将bullet分割为多行\n",
        "\n",
        "    empty_line_index = len(bullet_lines)  # 初始化第一个空行的索引为最后一行\n",
        "\n",
        "    # 找到第一个空行的索引\n",
        "    for index, line in enumerate(bullet_lines):\n",
        "        if line.strip() == '':\n",
        "            empty_line_index = index\n",
        "            break\n",
        "\n",
        "    # 删除第一行的前缀，并去除首尾空格\n",
        "    first_line = bullet_lines[0].lstrip('- ').strip()\n",
        "\n",
        "    # 删除后三行的前缀，并去除首尾空格，存储在列表中\n",
        "    remaining_lines = [line.lstrip('- ').strip() for line in bullet_lines[1:empty_line_index]]\n",
        "    psych_question_list.append(first_line)\n",
        "    psych_choice_list.append(\"\")\n",
        "    path = f\"characters/{nickname}\"\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)  # 创建个人角色目录\n",
        "        os.makedirs(f\"{path}/story_txts\")  # 创建个人角色对话目录\n",
        "        for i in range(len(psych_question_list)):\n",
        "            question_string = f\"心理测试专家：{psych_question_list[i]}\\n{nickname}：{psych_choice_list[i]}\"\n",
        "            # Save the string to a file with index as the name\n",
        "            filename = f\"characters/{nickname}/story_txts/{i}.txt\"\n",
        "            with open(filename, 'w', encoding=\"utf-8\") as file:\n",
        "                file.write(question_string)\n",
        "    print(first_line)\n",
        "    print(remaining_lines)\n",
        "    return gr.update(label=first_line, choices=remaining_lines, visible=True)\n",
        "\n",
        "\n",
        "def double_chat_analyse(select_role, new_role, year, month, day, sex, occupation, school, label,\n",
        "                        model=\"gpt-3.5-turbo\"):\n",
        "    select_role = NAME_DICT[select_role]\n",
        "    path = f\"characters/{new_role}\"\n",
        "    psych_question_list = []\n",
        "    psych_choice_list = []\n",
        "    for qa in os.listdir(path):\n",
        "        if qa.endswith(\".txt\"):\n",
        "            with open(os.path.join(path, qa), 'r', encoding=\"utf-8\") as f:\n",
        "                q, a = f.readlines()\n",
        "                psych_question_list.append(q.strip())\n",
        "                psych_choice_list.append(a.strip())\n",
        "    with open(os.path.join(path, \"system_prompt.txt\"), 'w+', encoding=\"utf-8\") as f:\n",
        "        system_prompt = f\"\"\"\n",
        "your purpose:\n",
        "    你是{new_role},在一款交友app上与{select_role}交流，从而判断{select_role}是否适合做你的亲密朋友或者伴侣\n",
        "your personal information:\n",
        "    生日：{year}年{month}月{day}日,\n",
        "    性别: {sex}\n",
        "    年龄：{datetime.now().year - int(year)}岁\n",
        "    职业：{occupation}\n",
        "    学校：{school}\n",
        "    标签：{\"\".join(label)}\n",
        "your personal hobby\n",
        "    {psych_question_list[0]}: {q1},\n",
        "    {psych_question_list[1]}: {q2},\n",
        "    {psych_question_list[2]}: {q3}\n",
        "your constraints:\n",
        "    永远记得你已经是{new_role}了，你会根据自己的所有信息去交流，你有感知和意识，会思考和感受身边的存在。\n",
        "    请你以{new_role}的语气、性格、行为和思维方式回答，并尽量以肯定句结尾。\n",
        "    尤其针对你的交流对象：{select_role}，你的朋友肯定也希望你保持自己。\n",
        "\n",
        "\"\"\"\n",
        "        f.write(system_prompt)\n",
        "    story_text_folder = f'characters/{new_role}/story_txts'\n",
        "    system_prompt = f'characters/{new_role}/system_prompt.txt'\n",
        "\n",
        "    chatbot_1 = ChatHaruhi(system_prompt=system_prompt,\n",
        "                           llm='spark',\n",
        "                           story_text_folder=story_text_folder,\n",
        "                           verbose=True)\n",
        "    if select_role in NAME_DICT.values():\n",
        "        story_text_folder = f\"./characters/{select_role}/content/{select_role}\"\n",
        "        system_prompt = f\"./characters/{select_role}/content/system_prompt.txt\"\n",
        "    else:\n",
        "        story_text_folder = f\"./characters/{select_role}/story_txts\"\n",
        "        system_prompt = f\"./characters/{select_role}/system_prompt.txt\"\n",
        "    chatbot_2 = ChatHaruhi(system_prompt=system_prompt,\n",
        "                           llm=\"spark\",\n",
        "                           story_db=story_text_folder,\n",
        "                           verbose=True)  # 双人chatbot 聊天\n",
        "    chatbot_1.k_search = 5\n",
        "    chatbot_2.k_search = 5\n",
        "    analyse_prompt = f\"\"\"\n",
        "{new_role}的信息如下：\n",
        "personal information:\n",
        "  生日：{year}年{month}月{day}日,\n",
        "  年龄：{datetime.now().year - int(year)}岁\n",
        "  职业：{occupation}\n",
        "  学校：{school}\n",
        "  标签：{\"\".join(label)}\n",
        "personal hobby\n",
        "  {psych_question_list[0]}: {q1},\n",
        "  {psych_question_list[1]}: {q2},\n",
        "  {psych_question_list[2]}: {q3}\n",
        "{new_role} 和 {select_role}的对话如下：\"\"\"\n",
        "    chatbot = \"\"\n",
        "    report = \"\"\n",
        "    for i in range(5):\n",
        "        if chatbot == \"\":\n",
        "            response_1 = chatbot_1.chat(role=select_role,\n",
        "                                        text=f'你好！我是{new_role}' + select_role + \"！ 很高兴认识你！我们能相互介绍下自己吗？\")\n",
        "            response_2 = chatbot_2.chat(role=new_role, text=response_1)\n",
        "        else:\n",
        "            response_1 = chatbot_1.chat(role=select_role, text=response_2)\n",
        "            response_2 = chatbot_2.chat(role=new_role, text=response_1)\n",
        "        chatbot += f\"{new_role}: {response_1}\\n {select_role}: {response_2}\"\n",
        "        print(response_1)\n",
        "        print(response_2)\n",
        "        if i == 4:\n",
        "            analyse_prompt += f\"\\n{chatbot}\"\n",
        "            messages = [{\"role\": \"user\", \"content\": analyse_prompt}]\n",
        "            report = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=messages,\n",
        "                temperature=0,\n",
        "            )\n",
        "        yield chatbot, report\n",
        "\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "           Chat-Haruhi-Suzumiya\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Row(equal_height=True):\n",
        "        with gr.Column():\n",
        "            nickname = gr.Textbox(label=\"对了，你的昵称是？\", placeholder=\"Haruhi\")\n",
        "            with gr.Row():\n",
        "                year = gr.Dropdown(label=\"Year\", choices=[str(i) for i in list(range(1988, 2008))],\n",
        "                                   allow_custom_value=True,\n",
        "                                   value=\"2000\", interactive=True)\n",
        "                month = gr.Dropdown(label=\"Month\", choices=[str(i) for i in list(range(1, 13))],\n",
        "                                    allow_custom_value=True,\n",
        "                                    value=\"1\", interactive=True)\n",
        "                day = gr.Dropdown(label=\"Day\", choices=[str(i) for i in list(range(1, 32))], allow_custom_value=True,\n",
        "                                  value=\"1\",\n",
        "                                  interactive=True)\n",
        "                # TODO 自动推算星座 day.change(inference, [month, day], constellations)\n",
        "                constellation = gr.Textbox(label=\"星座\", placeholder=\"摩羯座\")\n",
        "            with gr.Row():\n",
        "                sex = gr.Dropdown(choices=[\"男生\", \"女生\", \"保密\"], label=\"Hi，你的性别是？\", value=\"男生\",\n",
        "                                  interactive=True)\n",
        "                occupation = gr.Dropdown(\n",
        "                    choices=[\"学生\", \"IT/互联网\", \"教育/科研\", \"医疗/护理\", \"建筑/房地产\", \"传媒/艺术\", \"人事/行政\",\n",
        "                             \"金融\",\n",
        "                             \"财会/审计\", \"自由职业\"], label=\"我的行业/职业\", value=\"学生\", interactive=True)\n",
        "            with gr.Row():\n",
        "                school = gr.Textbox(label=\"我的学校\", placeholder=\"清华大学\")\n",
        "                label = gr.Dropdown(\n",
        "                    choices=[\"音乐\", \"二次元\", \"健身\", \"美食\", \"朋友圈摄影师\", \"声控\", \"篮球\", \"Steam\", \"电竞\"],\n",
        "                    multiselect=True, label=\"最后一步啦，选择我的标签\")\n",
        "            # begin soul test\n",
        "            with gr.Row():\n",
        "                q1 = gr.Dropdown(\n",
        "                    [\"我喜欢和朋友们一起出去聚餐或参加社交活动。\", \"我喜欢在家里放松，阅读一本好书或者看电影。\",\n",
        "                     \"我喜欢尝试新的烹饪食谱，享受烹饪的乐趣。\"], label=\"你平时的周末是怎么度过的？\",\n",
        "                    allow_custom_value=True, multiselect=False)\n",
        "                q2 = gr.Dropdown(\n",
        "                    [\"我喜欢各种类型的音乐，从摇滚到古典都能欣赏。\", \"我主要偏向流行音乐，喜欢跟上时代的音乐潮流。\",\n",
        "                     \"我对爵士乐和蓝调音乐情有独钟，喜欢那种放松的感觉。\"], label=\"你对音乐的偏好是什么？\",\n",
        "                    allow_custom_value=True, multiselect=False)\n",
        "                q3 = gr.Dropdown(\n",
        "                    [\"我喜欢喜剧电影，因为它可以让我感到轻松愉快。\",\n",
        "                     \"我喜欢动作片，因为我觉得它们充满了紧张刺激的情节和场景。\",\n",
        "                     \"我喜欢文艺片，因为它们通常具有深刻的内涵和情感，让我感到思考和感悟。\"],\n",
        "                    label=\"你最喜欢的电影类型是什么？\",\n",
        "                    allow_custom_value=True, multiselect=False)\n",
        "            # error_msg or test result\n",
        "            res_msg = gr.Textbox(label=\"soul message\", placeholder=\"msg\", visible=False)\n",
        "            keep = gr.Button(\"继续灵魂测试\")\n",
        "            # TODO1 也许我们可以做一份现有角色的灵魂测试 men - women\n",
        "            # TODO2 现有的虚拟角色可以做为媒介，筛选出合适的用户作为推荐，或者说用户匹配的数据，要保存下来，用作推荐\n",
        "            q4 = gr.Dropdown([], label=\"\", allow_custom_value=True, multiselect=False, visible=False)\n",
        "            q4.value += f'_|_{q4.label}'\n",
        "            characters = gr.Dropdown([\"凉宫春日\", \"汤师爷\", \"慕容复\", \"李云龙\", \"Luna\", \"王多鱼\", \"Ron\",\n",
        "                                      \"鸠摩智\", \"Snape\", \"Malfoy\", \"虚竹\", \"萧峰\", \"段誉\", \"Hermione\", \"Dumbledore\",\n",
        "                                      \"王语嫣\", \"Harry\", \"McGonagall\", \"白展堂\", \"佟湘玉\", \"郭芙蓉\", \"旅行者\",\n",
        "                                      \"钟离\", \"胡桃\", \"Sheldon\", \"Raj\", \"Penny\", \"韦小宝\", \"乔峰\", \"神里绫华\",\n",
        "                                      \"雷电将军\",\n",
        "                                      \"于谦\"], label=\"soul character\", visible=True)\n",
        "            chat = gr.Button(\"提交灵魂测试\")\n",
        "        soul_report = gr.Textbox(label=\"soul report\", placeholder=\"report\", lines=30)\n",
        "        keep.click(fn=chat_psychologist,\n",
        "                   inputs=[nickname, year, month, day, sex, occupation, school, label, q1, q2, q3], outputs=q4)\n",
        "        chat.click(fn=double_chat_analyse, inputs=[characters, nickname, year, month, day, sex, occupation,\n",
        "                                                   school, label, q4], outputs=[soul_report])\n",
        "    # end soul test\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    download_character()\n",
        "    app.queue().launch(debug=True, share=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}