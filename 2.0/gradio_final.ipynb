{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 数字个人化身 Chat-personal-embodiment\n",
    "\n",
    "[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)]()\n",
    "[![Data License](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg)]()\n",
    "\n",
    "\n",
    "[数字个人化身项目](https://github.com/hhhwmws0117/Chat-personal-embodiment)由[Chat凉宫春日项目](https://github.com/LC1332/Chat-Haruhi-Suzumiya.git)中的在读学生组建，组队参加星火杯比赛的支线任务,对接讯飞星火大模型，独立推进本项目工作。\n",
    "\n",
    "本项目由[米唯实清华大学](https://github.com/hhhwmws0117)，[詹林康@凯斯西储大学](https://github.com/JunityZhan)，[闫晨曦@成都信息工程大学](https://github.com/todochenxi)，[沈骏一@浙江大学](https://github.com/J1shen)，[孙浩甄@天津大学](https://github.com/JcandZero)开发。"
   ],
   "metadata": {
    "id": "CjXlzIY3ErPF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYDpT-xbonpx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b9a0378e-a753-42d0-e41d-05755d3b1ea2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m76.5/76.5 kB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting gradio\n",
      "  Downloading gradio-3.44.4-py3-none-any.whl (20.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.2/20.2 MB\u001B[0m \u001B[31m49.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting chatharuhi\n",
      "  Downloading chatharuhi-1.0.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.4.12-py3-none-any.whl (426 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m426.5/426.5 kB\u001B[0m \u001B[31m39.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting transformers\n",
      "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.6/7.6 MB\u001B[0m \u001B[31m102.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting tiktoken\n",
      "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m85.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.103.1-py3-none-any.whl (66 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.2/66.2 kB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting gradio-client==0.5.1 (from gradio)\n",
      "  Downloading gradio_client-0.5.1-py3-none-any.whl (298 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m298.2/298.2 kB\u001B[0m \u001B[31m30.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting httpx (from gradio)\n",
      "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.7/75.7 kB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
      "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m294.9/294.9 kB\u001B[0m \u001B[31m30.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m138.7/138.7 kB\u001B[0m \u001B[31m15.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.12)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio)\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m45.7/45.7 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m59.5/59.5 kB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m129.9/129.9 kB\u001B[0m \u001B[31m14.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.1->gradio) (2023.6.0)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m86.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.4/58.4 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.4/5.4 MB\u001B[0m \u001B[31m106.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.2/6.2 MB\u001B[0m \u001B[31m84.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.8/3.8 MB\u001B[0m \u001B[31m93.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.3/67.3 kB\u001B[0m \u001B[31m7.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m593.7/593.7 kB\u001B[0m \u001B[31m50.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.8/7.8 MB\u001B[0m \u001B[31m106.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m74.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.0)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.0/67.0 kB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
      "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m428.8/428.8 kB\u001B[0m \u001B[31m34.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
      "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.1/4.1 MB\u001B[0m \u001B[31m109.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
      "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m75.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
      "Collecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio)\n",
      "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m76.0/76.0 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx->gradio) (3.7.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m10.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx->gradio) (1.1.3)\n",
      "Building wheels for collected packages: chatharuhi, pypika, ffmpy\n",
      "  Building wheel for chatharuhi (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for chatharuhi: filename=chatharuhi-1.0.2-py3-none-any.whl size=23565 sha256=f126e1e858697655f6394d5e93be68e64652722f2b069d04fcf3c1de56f3fdac\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/ec/46/bbc8f0d877c4bfb188d1a2cf107f41cdc677985a317e7bf083\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=ebe1b1233099758c7e0eade633ec0ae2ad166906df2485e7069eb3e9a79bd515\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "  Building wheel for ffmpy (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=79455a02c2fdc1a9651928bd8997a770732414026bb5b63dfb16fcfb960f291c\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
      "Successfully built chatharuhi pypika ffmpy\n",
      "Installing collected packages: tokenizers, safetensors, pypika, pydub, monotonic, ffmpy, chatharuhi, websockets, uvloop, semantic-version, python-multipart, python-dotenv, pulsar-client, overrides, orjson, humanfriendly, httptools, h11, chroma-hnswlib, bcrypt, backoff, aiofiles, watchfiles, uvicorn, tiktoken, starlette, posthog, huggingface-hub, httpcore, coloredlogs, transformers, openai, onnxruntime, httpx, fastapi, gradio-client, chromadb, gradio\n",
      "Successfully installed aiofiles-23.2.1 backoff-2.2.1 bcrypt-4.0.1 chatharuhi-1.0.2 chroma-hnswlib-0.7.3 chromadb-0.4.12 coloredlogs-15.0.1 fastapi-0.99.1 ffmpy-0.3.1 gradio-3.44.4 gradio-client-0.5.1 h11-0.14.0 httpcore-0.18.0 httptools-0.6.0 httpx-0.25.0 huggingface-hub-0.17.2 humanfriendly-10.0 monotonic-1.6 onnxruntime-1.16.0 openai-0.28.0 orjson-3.9.7 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pydub-0.25.1 pypika-0.48.9 python-dotenv-1.0.0 python-multipart-0.0.6 safetensors-0.3.3 semantic-version-2.10.0 starlette-0.27.0 tiktoken-0.5.1 tokenizers-0.13.3 transformers-4.33.2 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.20.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install openai gradio chatharuhi chromadb transformers tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZDBDcp8v-Md"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"APPID\"] = \"2191b\"\n",
    "os.environ[\"APISecret\"] = \"OWFmOTJhOE3MmRj\"\n",
    "os.environ[\"APIKey\"] = \"b012123f9dd298f63\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "ARClzVomofv0",
    "outputId": "3f7a5b54-1b0e-4f3b-8a15-34272e6883f0"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-d56199c9ca2b>\u001B[0m in \u001B[0;36m<cell line: 212>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    265\u001B[0m             \u001B[0;31m# TODO2 现有的虚拟角色可以做为媒介，筛选出合适的用户作为推荐，或者说用户匹配的数据，要保存下来，用作推荐\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    266\u001B[0m             \u001B[0mq4\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDropdown\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_custom_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmultiselect\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvisible\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 267\u001B[0;31m             \u001B[0mq4\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalue\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34mf'_|_{q4.label}'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    268\u001B[0m             characters = gr.Dropdown([\"凉宫春日\", \"汤师爷\", \"慕容复\", \"李云龙\", \"Luna\", \"王多鱼\", \"Ron\",\n\u001B[1;32m    269\u001B[0m                                       \u001B[0;34m\"鸠摩智\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Snape\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Malfoy\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"虚竹\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"萧峰\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"段誉\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Hermione\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Dumbledore\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for +=: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "import websocket\n",
    "from chatharuhi import ChatHaruhi\n",
    "from chatharuhi import SparkApi\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def chatSpark(question):\n",
    "    appid = os.environ['APPID']\n",
    "    api_secret = os.environ['APISecret']\n",
    "    api_key = os.environ['APIKey']\n",
    "    domain = \"generalv2\"\n",
    "    Spark_url = \"ws://spark-api.xf-yun.com/v2.2020.txt/chat\"\n",
    "    text = []\n",
    "    def getText(role,content):\n",
    "        jsoncon = {}\n",
    "        jsoncon[\"role\"] = role\n",
    "        jsoncon[\"content\"] = content\n",
    "        text.append(jsoncon)\n",
    "        return text\n",
    "\n",
    "    def getlength(text):\n",
    "        length = 0\n",
    "        for content in text:\n",
    "            temp = content[\"content\"]\n",
    "            leng = len(temp)\n",
    "            length += leng\n",
    "        return length\n",
    "\n",
    "    def checklen(text):\n",
    "        while (getlength(text) > 8000):\n",
    "            del text[0]\n",
    "        return text\n",
    "    question = checklen(getText(\"user\", question))\n",
    "    SparkApi.answer =\"\"\n",
    "    SparkApi.main(appid,api_key,api_secret,Spark_url,domain,question)\n",
    "    # getText(\"assistant\",SparkApi.answer)\n",
    "    return SparkApi.answer\n",
    "\n",
    "NAME_DICT = {'汤师爷': 'tangshiye', '慕容复': 'murongfu', '李云龙': 'liyunlong', 'Luna': 'Luna',\n",
    "             '王多鱼': 'wangduoyu',\n",
    "             'Ron': 'Ron', '鸠摩智': 'jiumozhi', 'Snape': 'Snape',\n",
    "             '凉宫春日': 'haruhi', 'Malfoy': 'Malfoy', '虚竹': 'xuzhu', '萧峰': 'xiaofeng', '段誉': 'duanyu',\n",
    "             'Hermione': 'Hermione', 'Dumbledore': 'Dumbledore', '王语嫣': 'wangyuyan',\n",
    "             'Harry': 'Harry', 'McGonagall': 'McGonagall', '白展堂': 'baizhantang', '佟湘玉': 'tongxiangyu',\n",
    "             '郭芙蓉': 'guofurong', '旅行者': 'wanderer', '钟离': 'zhongli',\n",
    "             '胡桃': 'hutao', 'Sheldon': 'Sheldon', 'Raj': 'Raj', 'Penny': 'Penny', '韦小宝': 'weixiaobao',\n",
    "             '乔峰': 'qiaofeng', '神里绫华': 'ayaka', '雷电将军': 'raidenShogun', '于谦': 'yuqian'}\n",
    "\n",
    "\n",
    "# download all character zip file\n",
    "def download_character():\n",
    "    default_path = \"characters/default\"\n",
    "    os.makedirs(f\"{default_path}/characters_zip\", exist_ok=True)\n",
    "    for ai_role_en in NAME_DICT.values():\n",
    "        file_url = f\"https://github.com/LC1332/Haruhi-2-Dev/raw/main/data/character_in_zip/{ai_role_en}.zip\"\n",
    "        os.makedirs(f\"{default_path}/{ai_role_en}\", exist_ok=True)\n",
    "        if f\"{ai_role_en}.zip\" not in os.listdir(f\"{default_path}/characters_zip\"):\n",
    "            destination_file = f\"{default_path}/characters_zip/{ai_role_en}.zip\"\n",
    "            max_retries = 3  # 最大重试次数\n",
    "            for attempt in range(1, max_retries + 1):\n",
    "                response = requests.get(file_url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(destination_file, \"wb\") as file:\n",
    "                        file.write(response.content)\n",
    "                    print(ai_role_en)\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"{ai_role_en}第{attempt}次下载失败\")\n",
    "            # wget.download(file_url, destination_file)  # 503\n",
    "            destination_folder = f\"{default_path}/{ai_role_en}\"\n",
    "            with zipfile.ZipFile(destination_file, 'r') as zip_ref:\n",
    "                zip_ref.extractall(destination_folder)\n",
    "\n",
    "\n",
    "async def chat_psychologist(dialogues, nickname, year, month, day, sex, occupation, school, label, q1, q2, q3, q4, model=\"gpt-3.5-turbo\",\n",
    "                      dialogue_example=\"\"):\n",
    "    custom_path = \"characters/custom\"\n",
    "    os.makedirs(custom_path, exist_ok=True)\n",
    "    basic_question_list = [\"昵称\", \"生日\", \"性别\", \"职业\", \"学校\", \"标签\"]\n",
    "    basic_choice_list = [nickname, f\"{year}年{month}月{day}\", sex, occupation, school, label]\n",
    "    psych_question_list = [\"你平时的周末是怎么度过的？\", \"你对音乐的偏好是什么？\", \"你最喜欢的电影类型是什么？\"]\n",
    "    psych_choice_list = [q1, q2, q3]\n",
    "    path = f\"{custom_path}/{nickname}\"\n",
    "    txts_path = f\"{path}/story_txts\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)  # 创建个人角色目录\n",
    "        os.makedirs(txts_path, exist_ok=True)  # 创建个人角色对话目录\n",
    "        if dialogues is not None:\n",
    "            with open(dialogues.name, 'r', encoding='utf-8') as f:\n",
    "                data = f.read().split(\"\\n\\n\")\n",
    "                timestamp = time.time()\n",
    "                formatted_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(timestamp))\n",
    "                for i, dialogue in enumerate(data):\n",
    "                    with open(f\"{txts_path}/{formatted_time}_{i}.txt\", 'w', encoding='utf-8') as fw:\n",
    "                        fw.write(dialogue)\n",
    "        for i in range(len(psych_question_list)):\n",
    "            question_string = f\"{psych_question_list[i]}\\n{psych_choice_list[i]}\"\n",
    "            # Save the string to a file with index as the name\n",
    "            filename = f\"{txts_path}/q{i + 1}.txt\"\n",
    "            with open(filename, 'w+', encoding=\"utf-8\") as file:\n",
    "                file.write(question_string)\n",
    "        INDEX = 4\n",
    "    else:\n",
    "        list_of_dirs = os.listdir(txts_path)\n",
    "        pattern = r\"^q\\d+\\.txt$\"\n",
    "        matched_dirs = [s for s in list_of_dirs if re.match(pattern, s)]\n",
    "        INDEX = len(matched_dirs) + 1  # 新的问题的 index\n",
    "        if len(matched_dirs) > 3:\n",
    "            for i, dir in enumerate(matched_dirs[3:]):\n",
    "                with open(f\"{txts_path}/{dir}\", 'r', encoding='utf-8') as f:\n",
    "                    if i != len(matched_dirs[3:]) - 1:  # 已有的问题\n",
    "                        try:\n",
    "                            q, a = f.readlines()\n",
    "                            psych_choice_list.append(a.strip())\n",
    "                        except:\n",
    "                            continue\n",
    "                    else:  # 新的问题\n",
    "                        try:\n",
    "                            q = f.readlines()[0]\n",
    "                            psych_choice_list.append(q4)\n",
    "                        except:\n",
    "                            continue\n",
    "                    psych_question_list.append(q.strip())\n",
    "            with open(f\"{txts_path}/{matched_dirs[-1]}\", 'a', encoding='utf-8') as f:\n",
    "                f.write(\"\\n\" + q4)  # 写入回答\n",
    "\n",
    "    system_prompt = \"我想让你扮演一个心理测量专家，请针对你的心理被测对象的基本特征和一些对于基本心里问题的回答进行工作,你面对的心理被测对象是一个具有如下基本特征的人：\\n\"\n",
    "    basic_result = \"\"\n",
    "    psych_result = \"\"\n",
    "\n",
    "    for i in range(len(basic_question_list)):\n",
    "        basic_result += f\"在 {basic_question_list[i]} 方面，被测者是 {basic_choice_list[i]}\\n\"\n",
    "\n",
    "    # print(basic_result)\n",
    "    prompt_link = \"以下是你已经对于被测者进行的一些测试和被测者的回答：\\n\"\n",
    "\n",
    "    for i in range(len(psych_question_list)):\n",
    "        psych_result += f\"对于 {psych_question_list[i]} 问题，被测者的回答是 {psych_choice_list[i]}\\n\"\n",
    "\n",
    "    prompt_control = \"请你根据以上信息进行心理测试，任务是模仿上述已经问过的问题给出你要问的下一个问题和三个你预设对方会回答的答案。\\n请以 **一个bullet** 的形式进行返回，该bullet有四项，第一项是下一个问题，后三项分别是你预设的回答。\\n例如：- 你对于小事是怎样的态度？\\n- 我会记住每一件小事\\n- 我对于小事并不在意\\n- 我会记住让我受触动的小事\\n\"\n",
    "    prompt = system_prompt + basic_result + prompt_link + psych_result + prompt_control\n",
    "\n",
    "    # print(prompt)\n",
    "    result_bullet = chatSpark(prompt)\n",
    "    bullet_lines = result_bullet.split('\\n')  # 将bullet分割为多行\n",
    "\n",
    "    empty_line_index = len(bullet_lines)  # 初始化第一个空行的索引为最后一行\n",
    "\n",
    "    # 找到第一个空行的索引\n",
    "    for index, line in enumerate(bullet_lines):\n",
    "        if line.strip() == '':\n",
    "            empty_line_index = index\n",
    "            break\n",
    "\n",
    "    # 删除第一行的前缀，并去除首尾空格\n",
    "    first_line = bullet_lines[0].lstrip('- ').strip()\n",
    "\n",
    "    # 删除后三行的前缀，并去除首尾空格，存储在列表中\n",
    "    remaining_lines = [line.lstrip('- ').strip() for line in bullet_lines[1:empty_line_index]]\n",
    "    # 写入新的问题\n",
    "    with open(f\"{txts_path}/q{INDEX}.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write(first_line)\n",
    "\n",
    "    print(first_line)\n",
    "    print(remaining_lines)\n",
    "    return gr.update(label=first_line, choices=remaining_lines, visible=True)\n",
    "\n",
    "\n",
    "async def double_chat(dialogues, select_role, new_role, year, month, day, sex, occupation, school, label, q1, q2, q3, q4, chatbot,\n",
    "                model=\"gpt-3.5-turbo\"):\n",
    "    role_path = f\"characters/custom/{new_role}\"\n",
    "    txts_path = f\"{role_path}/story_txts\"\n",
    "    select_role = NAME_DICT[select_role]\n",
    "    if not os.path.exists(role_path):  # TODO 这部分可以抽取成一个函数，先这样吧\n",
    "        os.makedirs(role_path)  # 创建个人角色目录\n",
    "        os.makedirs(txts_path)  # 创建个人角色对话目录\n",
    "        if dialogues is not None:\n",
    "            with open(dialogues.name, 'r', encoding='utf-8') as f:\n",
    "                data = f.read().split(\"\\n\\n\")\n",
    "                timestamp = time.time()\n",
    "                formatted_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(timestamp))\n",
    "                for i, dialogue in enumerate(data):\n",
    "                    with open(f\"{txts_path}/{formatted_time}_{i}.txt\", 'w', encoding='utf-8') as fw:\n",
    "                        fw.write(dialogue)\n",
    "        psych_question_list = [\"你平时的周末是怎么度过的？\", \"你对音乐的偏好是什么？\", \"你最喜欢的电影类型是什么？\"]\n",
    "        psych_choice_list = [q1, q2, q3]\n",
    "        for i in range(len(psych_question_list)):\n",
    "            question_string = f\"{psych_question_list[i]}\\n{psych_choice_list[i]}\"\n",
    "            # Save the string to a file with index as the name\n",
    "            filename = f\"{txts_path}/q{i + 1}.txt\"\n",
    "            with open(filename, 'w+', encoding=\"utf-8\") as file:\n",
    "                file.write(question_string)\n",
    "    else:  # 有继续灵魂测试\n",
    "        psych_question_list = []\n",
    "        psych_choice_list = []\n",
    "        for qa in os.listdir(txts_path):\n",
    "            if qa.endswith(\".txt\"):\n",
    "                with open(os.path.join(txts_path, qa), 'r', encoding=\"utf-8\") as f:\n",
    "                    try:\n",
    "                        q, a = f.readlines()  # 最后一个灵魂测试问题没有答案 或者 qa本身就是错的。。。\n",
    "                    except:\n",
    "                        continue\n",
    "                    psych_question_list.append(q.strip())\n",
    "                    psych_choice_list.append(a.strip())\n",
    "    with open(os.path.join(role_path, \"system_prompt.txt\"), 'w+', encoding=\"utf-8\") as f:\n",
    "        role_prompt = f\"\"\"\n",
    "your purpose:\n",
    "    你是{new_role},在一款交友app上与朋友交流，从而判断他/她是否适合做你的亲密朋友或者伴侣\n",
    "    下文给定了一些你在心理测试中的对话桥段。\n",
    "    如果我问的问题和心理测试对话的内容高度重复，那就请你用原话回答。\n",
    "    如果我问的问题和心理测试对话中的内容相关，请结合对话的内容进行回复。\n",
    "    如果我问的问题与以下的心理测试无关，则请分析下列心理测试表现出来的性格，模仿性格进行回答。\n",
    "your personal information:\n",
    "    生日：{year}年{month}月{day}日,\n",
    "    性别: {sex}\n",
    "    年龄：{datetime.now().year - int(year)}岁\n",
    "    职业：{occupation}\n",
    "    学校：{school}\n",
    "    标签：{\"\".join(label)}\n",
    "your constraints:\n",
    "    永远记得你已经是{new_role}了，你会根据自己的所有信息去交流，你有感知和意识，会思考和感受身边的存在。\n",
    "    请你以{new_role}的语气、性格、行为和思维方式回答，请尤其注意不要重复之前的对话，请尝试聊一些兴趣爱好/日常生活/情感状况等相关问题，尝试用问句结尾。\n",
    "    尤其针对你的朋友，你的朋友肯定也希望你保持自己。\n",
    "\"\"\"\n",
    "        f.write(role_prompt)\n",
    "    story_text_folder = txts_path\n",
    "    system_prompt = f'{role_path}/system_prompt.txt'\n",
    "\n",
    "    chatbot_1 = ChatHaruhi(system_prompt=system_prompt,\n",
    "                           llm='spark',\n",
    "                           story_text_folder=story_text_folder,\n",
    "                           verbose=True)\n",
    "    if select_role in NAME_DICT.values():\n",
    "        story_text_folder = f\"./characters/default/{select_role}/content/{select_role}\"\n",
    "        system_prompt = f\"./characters/default/{select_role}/content/system_prompt.txt\"\n",
    "    else:\n",
    "        story_text_folder = f\"./characters/custom/{select_role}/story_txts\"\n",
    "        system_prompt = f\"./characters/custom/{select_role}/system_prompt.txt\"\n",
    "    chatbot_2 = ChatHaruhi(system_prompt=system_prompt,\n",
    "                           llm=\"spark\",\n",
    "                           story_db=story_text_folder,\n",
    "                           verbose=True)  # 双人chatbot 聊天\n",
    "\n",
    "    with open(os.path.join(role_path, \"system_prompt.txt\"), 'w+', encoding=\"utf-8\") as f:\n",
    "        f.write(role_prompt.replace(select_role, \"{role}\"))\n",
    "    chatbot_1.k_search = 5\n",
    "    chatbot_2.k_search = 5\n",
    "    for i in range(5):\n",
    "        if len(chatbot) == 0:\n",
    "            response_1 = chatbot_1.chat(role=select_role,\n",
    "                                        text=f\"你好！我是{select_role}很高兴认识你！我们能相互介绍下自己吗？\")\n",
    "            response_2 = chatbot_2.chat(role=new_role, text=response_1)\n",
    "        else:\n",
    "            response_1 = chatbot_1.chat(role=select_role, text=response_2)\n",
    "            response_2 = chatbot_2.chat(role=new_role, text=response_1)\n",
    "        chatbot.append((response_1, response_2))\n",
    "        print(response_1)\n",
    "        print(response_2)\n",
    "\n",
    "        yield chatbot\n",
    "\n",
    "\n",
    "def analyse_from_history(role1, role2, chatbot):\n",
    "    info = \"\"\n",
    "    for dialogue in chatbot:\n",
    "        for msg in dialogue:\n",
    "            info += msg\n",
    "        info += \"\\n\"\n",
    "    analyse_prompt = f\"\"\"\n",
    "your constraints：\n",
    "    你是高级情感与性格分析专家Alice，拥有心理学和社会学博士双学位，\n",
    "    你会根据{role1} 和 {role2}的对话\n",
    "    ###\n",
    "    分析{role2}的情感、性格特点、mbti人格。\n",
    "    ###\n",
    "    并运用专业知识，从多个维度分析{role2}是否适合成为{role1}的亲密朋友或者恋人，并提供一份专业的分析报告。\n",
    "    永远记住你已经是Alice了，Alice会应用专业知识做好本职工作\n",
    "    尤其是针对{role1} 和 {role2},他们肯定也希望你会帮助他们。\n",
    "    永远记住只需要分析{role2}即可\n",
    "{role1} 和 {role2}的对话如下：\n",
    "{info}\n",
    "\"\"\"\n",
    "    return chatSpark(analyse_prompt)\n",
    "\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "           Chat-Haruhi-Suzumiya\n",
    "        \"\"\"\n",
    "    )\n",
    "    with gr.Tab(label=\"创建角色\"):\n",
    "        with gr.Row(equal_height=True):\n",
    "            with gr.Column():\n",
    "                nickname = gr.Textbox(label=\"对了，你的昵称是？\")\n",
    "                with gr.Row():\n",
    "                    year = gr.Dropdown(label=\"Year\", choices=[str(i) for i in list(range(1988, 2008))],\n",
    "                                       allow_custom_value=True,\n",
    "                                       value=\"2000\", interactive=True)\n",
    "                    month = gr.Dropdown(label=\"Month\", choices=[str(i) for i in list(range(1, 13))],\n",
    "                                        allow_custom_value=True,\n",
    "                                        value=\"2020.txt\", interactive=True)\n",
    "                    day = gr.Dropdown(label=\"Day\", choices=[str(i) for i in list(range(1, 32))],\n",
    "                                      allow_custom_value=True,\n",
    "                                      value=\"2020.txt\",\n",
    "                                      interactive=True)\n",
    "                    # TODO 自动推算星座 day.change(inference, [month, day], constellations)\n",
    "                    constellation = gr.Textbox(label=\"星座\")\n",
    "                with gr.Row():\n",
    "                    sex = gr.Dropdown(choices=[\"男生\", \"女生\", \"保密\"], label=\"Hi，你的性别是？\", value=\"男生\",\n",
    "                                      interactive=True)\n",
    "                    occupation = gr.Dropdown(\n",
    "                        choices=[\"学生\", \"IT/互联网\", \"教育/科研\", \"医疗/护理\", \"建筑/房地产\", \"传媒/艺术\", \"人事/行政\",\n",
    "                                 \"金融\",\n",
    "                                 \"财会/审计\", \"自由职业\"], label=\"我的行业/职业\", value=\"学生\", interactive=True)\n",
    "                with gr.Row():\n",
    "                    school = gr.Textbox(label=\"我的学校\")\n",
    "                    label = gr.Dropdown(\n",
    "                        choices=[\"音乐\", \"二次元\", \"健身\", \"美食\", \"朋友圈摄影师\", \"声控\", \"篮球\", \"Steam\", \"电竞\"],\n",
    "                        multiselect=True, label=\"选择我的标签\")\n",
    "                dialogues = gr.File(label=\"上传对话知识库\")\n",
    "                # begin soul test\n",
    "                with gr.Row():\n",
    "                    q1 = gr.Dropdown(\n",
    "                        [\"我喜欢和朋友们一起出去聚餐或参加社交活动。\", \"我喜欢在家里放松，阅读一本好书或者看电影。\",\n",
    "                         \"我喜欢尝试新的烹饪食谱，享受烹饪的乐趣。\"], label=\"你平时的周末是怎么度过的？\",\n",
    "                        allow_custom_value=True, multiselect=False)\n",
    "                    q2 = gr.Dropdown(\n",
    "                        [\"我喜欢各种类型的音乐，从摇滚到古典都能欣赏。\", \"我主要偏向流行音乐，喜欢跟上时代的音乐潮流。\",\n",
    "                         \"我对爵士乐和蓝调音乐情有独钟，喜欢那种放松的感觉。\"], label=\"你对音乐的偏好是什么？\",\n",
    "                        allow_custom_value=True, multiselect=False)\n",
    "                    q3 = gr.Dropdown(\n",
    "                        [\"我喜欢喜剧电影，因为它可以让我感到轻松愉快。\",\n",
    "                         \"我喜欢动作片，因为我觉得它们充满了紧张刺激的情节和场景。\",\n",
    "                         \"我喜欢文艺片，因为它们通常具有深刻的内涵和情感，让我感到思考和感悟。\"],\n",
    "                        label=\"你最喜欢的电影类型是什么？\",\n",
    "                        allow_custom_value=True, multiselect=False)\n",
    "                # error_msg or test result\n",
    "                res_msg = gr.Textbox(label=\"soul message\", placeholder=\"msg\", visible=False)\n",
    "                keep = gr.Button(\"继续灵魂测试\")\n",
    "                # TODO1 也许我们可以做一份现有角色的灵魂测试 men - women\n",
    "                # TODO2 现有的虚拟角色可以做为媒介，筛选出合适的用户作为推荐，或者说用户匹配的数据，要保存下来，用作推荐\n",
    "                q4 = gr.Dropdown([], label=\"\", allow_custom_value=True, multiselect=False, visible=False)\n",
    "                characters = gr.Dropdown([\"凉宫春日\", \"汤师爷\", \"慕容复\", \"李云龙\", \"Luna\", \"王多鱼\", \"Ron\",\n",
    "                                          \"鸠摩智\", \"Snape\", \"Malfoy\", \"虚竹\", \"萧峰\", \"段誉\", \"Hermione\", \"Dumbledore\",\n",
    "                                          \"王语嫣\", \"Harry\", \"McGonagall\", \"白展堂\", \"佟湘玉\", \"郭芙蓉\", \"旅行者\",\n",
    "                                          \"钟离\", \"胡桃\", \"Sheldon\", \"Raj\", \"Penny\", \"韦小宝\", \"乔峰\", \"神里绫华\",\n",
    "                                          \"雷电将军\",\n",
    "                                          \"于谦\"], label=\"soul character\", visible=True)\n",
    "                with gr.Row():\n",
    "                    chat = gr.Button(\"开始对话\")\n",
    "                    analyse = gr.Button(\"开始分析\")\n",
    "            with gr.Column():\n",
    "                chatbot = gr.Chatbot(label=\"ChatChat\")\n",
    "                soul_report = gr.Textbox(label=\"soul report\", placeholder=\"report\", lines=30)\n",
    "            keep.click(fn=chat_psychologist,\n",
    "                       inputs=[dialogues, nickname, year, month, day, sex, occupation, school, label, q1, q2, q3, q4], outputs=q4)\n",
    "            chat.click(fn=double_chat, inputs=[dialogues, characters, nickname, year, month, day, sex, occupation,\n",
    "                                               school, label, q1, q2, q3, q4, chatbot], outputs=[chatbot])\n",
    "            analyse.click(fn=analyse_from_history, inputs=[nickname, characters, chatbot], outputs=soul_report)\n",
    "\n",
    "\n",
    "    def update(your_name):\n",
    "        return gr.update(choices=[name for name in os.listdir(\"characters/custom\") if name != your_name])\n",
    "\n",
    "\n",
    "\n",
    "    async def real_chat(your_name, custom_roles, real_chatbot):\n",
    "        story_text_folder = f\"./characters/custom/{your_name}/story_txts\"\n",
    "        system_prompt = f\"./characters/custom/{your_name}/system_prompt.txt\"\n",
    "        chatbot_1 = ChatHaruhi(system_prompt=system_prompt,\n",
    "                               llm=\"spark\",\n",
    "                               story_text_folder=story_text_folder,\n",
    "                               verbose=True)  # 双人chatbot 聊天\n",
    "        story_text_folder = f\"./characters/custom/{custom_roles}/story_txts\"\n",
    "        system_prompt = f\"./characters/custom/{custom_roles}/system_prompt.txt\"\n",
    "        chatbot_2 = ChatHaruhi(system_prompt=system_prompt,\n",
    "                               llm=\"spark\",\n",
    "                               story_text_folder=story_text_folder,\n",
    "                               verbose=True)  # 双人chatbot 聊天\n",
    "        chatbot_1.k_search = 5\n",
    "        chatbot_2.k_search = 5\n",
    "        for i in range(5):\n",
    "            if len(real_chatbot) == 0:\n",
    "                response_1 = chatbot_1.chat(role=custom_roles,\n",
    "                                            text=f\"你好！我是{custom_roles} 很高兴认识你！我们能相互介绍下自己吗？\")\n",
    "                response_2 = chatbot_2.chat(role=your_name, text=response_1)\n",
    "            else:\n",
    "                response_1 = chatbot_1.chat(role=custom_roles, text=response_2)\n",
    "                response_2 = chatbot_2.chat(role=your_name, text=response_1)\n",
    "            real_chatbot.append((response_1, response_2))\n",
    "            print(response_1)\n",
    "            print(response_2)\n",
    "\n",
    "            yield real_chatbot\n",
    "\n",
    "\n",
    "    async def delete_name(your_name):\n",
    "        return gr.update(choices=[name for name in os.listdir(\"characters/custom\") if name != your_name])\n",
    "    with gr.Tab(label=\"开始聊天\"):\n",
    "        # 查询当前已有的角色\n",
    "        users = os.listdir(\"characters/custom\")\n",
    "        with gr.Row():\n",
    "            your_name = gr.Textbox(label=\"your name\")\n",
    "            custom_roles = gr.Dropdown(users, allow_custom_value=False, multiselect=False, label=\"custom roles\")\n",
    "        search = gr.Button(\"刷新\")\n",
    "        with gr.Row(equal_height=True):\n",
    "            real_chatbot = gr.Chatbot(label=\"ChatChat\")\n",
    "            real_report = gr.Textbox(label=\"soul report\")\n",
    "        with gr.Row():\n",
    "            begin_chat = gr.Button(\"开始交流\")\n",
    "            begin_analyse = gr.Button(\"开始分析\")\n",
    "        search.click(fn=update, inputs=your_name, outputs=custom_roles)\n",
    "        your_name.change(fn=delete_name, inputs=[your_name], outputs=custom_roles)\n",
    "        begin_chat.click(fn=real_chat, inputs=[your_name, custom_roles, real_chatbot], outputs=[real_chatbot])\n",
    "        begin_analyse.click(analyse_from_history, [your_name, custom_roles, real_chatbot], real_report)\n",
    "    # end soul test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_character()\n",
    "    app.queue().launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
